{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843d6a0a-7d7b-4861-81cb-5c50630d010a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.8/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.8/site-packages (from accelerate) (0.20.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "Successfully installed accelerate-0.28.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83a9d5a4-7038-40c1-9944-f96ac72bb701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /opt/conda/lib/python3.8/site-packages (4.7.1)\n",
      "Collecting gdown\n",
      "  Downloading gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.8/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.8/site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from gdown) (4.65.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests[socks]->gdown) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests[socks]->gdown) (2023.11.17)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.8/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: gdown\n",
      "  Attempting uninstall: gdown\n",
      "    Found existing installation: gdown 4.7.1\n",
      "    Uninstalling gdown-4.7.1:\n",
      "      Successfully uninstalled gdown-4.7.1\n",
      "Successfully installed gdown-5.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4df510be-2ba3-4544-ae42-d9895b8eaf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5544418-77cf-4916-b226-d660cd8266d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1zevHeQSmjcxzXmf3hM2J5gmMkWO6ln4G .DS_Store\n",
      "Retrieving folder 14aJya_B62tGaHTnUFZgZ3c1vlrXKg2IK .ipynb_checkpoints\n",
      "Processing file 16nYJ28oHhn5TakEezE_sE2HTyJ-0hOpF EEG_loading-checkpoint.ipynb\n",
      "Processing file 1rl6zcMoHwsCXR11vmYXvtB2d2wyJt_6F main.ipynb\n",
      "Processing file 1krpg_1i1z7GkKmY5sfWxVZdeVVucSnNS person_test.npy\n",
      "Processing file 1z2uz75YfVfrLJ0rIfCPUYGI6mr_Xqxx_ person_train_valid.npy\n",
      "Processing file 1_I6GXMJDUveXoTPnlWRI2szoe5d7-YgE X_test.npy\n",
      "Processing file 1Z4cNncLvLGM9NBXF1vqSnOFJUmAbBJgM X_train_valid.npy\n",
      "Processing file 1levFOLOfv93OLosULZIFl8nhud-xZYm6 y_test.npy\n",
      "Processing file 1dpTmZCTyRMidjwSI2aa7SE4ne2uEgS-w y_train_valid.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1zevHeQSmjcxzXmf3hM2J5gmMkWO6ln4G\n",
      "To: /home/project/.DS_Store\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 6.15k/6.15k [00:00<00:00, 662kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=16nYJ28oHhn5TakEezE_sE2HTyJ-0hOpF\n",
      "To: /home/project/.ipynb_checkpoints/EEG_loading-checkpoint.ipynb\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 1.74k/1.74k [00:00<00:00, 5.70MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1rl6zcMoHwsCXR11vmYXvtB2d2wyJt_6F\n",
      "To: /home/project/main.ipynb\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 214k/214k [00:00<00:00, 2.51MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1krpg_1i1z7GkKmY5sfWxVZdeVVucSnNS\n",
      "To: /home/project/person_test.npy\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 3.67k/3.67k [00:00<00:00, 11.3MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1z2uz75YfVfrLJ0rIfCPUYGI6mr_Xqxx_\n",
      "To: /home/project/person_train_valid.npy\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17.0k/17.0k [00:00<00:00, 421kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1_I6GXMJDUveXoTPnlWRI2szoe5d7-YgE\n",
      "To: /home/project/X_test.npy\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 78.0M/78.0M [00:00<00:00, 80.2MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Z4cNncLvLGM9NBXF1vqSnOFJUmAbBJgM\n",
      "From (redirected): https://drive.google.com/uc?id=1Z4cNncLvLGM9NBXF1vqSnOFJUmAbBJgM&confirm=t&uuid=bf64cb85-3393-42e7-ab20-a5360477526f\n",
      "To: /home/project/X_train_valid.npy\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 372M/372M [00:05<00:00, 73.0MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1levFOLOfv93OLosULZIFl8nhud-xZYm6\n",
      "To: /home/project/y_test.npy\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 1.90k/1.90k [00:00<00:00, 6.08MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1dpTmZCTyRMidjwSI2aa7SE4ne2uEgS-w\n",
      "To: /home/project/y_train_valid.npy\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 8.59k/8.59k [00:00<00:00, 1.89MB/s]\n",
      "Download completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/project/.DS_Store',\n",
       " '/home/project/.ipynb_checkpoints/EEG_loading-checkpoint.ipynb',\n",
       " '/home/project/main.ipynb',\n",
       " '/home/project/person_test.npy',\n",
       " '/home/project/person_train_valid.npy',\n",
       " '/home/project/X_test.npy',\n",
       " '/home/project/X_train_valid.npy',\n",
       " '/home/project/y_test.npy',\n",
       " '/home/project/y_train_valid.npy']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "gdown.download_folder(id=\"1L1dX7CmLUbFPxsp37z7suGEmMxudeDwX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af4a610-1e7f-4ffa-8d29-b43470ec6ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"project/X_test.npy\")  # (443, 22, 1000)\n",
    "y_test = np.load(\"project/y_test.npy\")  # (443, 4)  # (num_trials, output types) # one hot encoded\n",
    "person_train_valid = np.load(\"project/person_train_valid.npy\")  # (2115, 1)  vals from 0-8 for participant\n",
    "X_train_valid = np.load(\"project/X_train_valid.npy\")  # (2115, 22, 1000)\n",
    "# print(X_train_valid.shape)  # (2115, 22, 1000)  # (num_trials, channels, time bins)x\n",
    "y_train_valid = np.load(\"project/y_train_valid.npy\")  # (2115,)\n",
    "person_test = np.load(\"project/person_test.npy\")  # (443, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8126b89-6a24-4e4e-8dcd-8c10e5e4afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_prep(X,y,sub_sample,average,noise):\n",
    "\n",
    "    total_X = None\n",
    "    total_y = None\n",
    "\n",
    "    # Trimming the data (sample,22,1000) -> (sample,22,800)\n",
    "    X = X[:,:,0:800]\n",
    "    print('Shape of X after trimming:',X.shape)\n",
    "\n",
    "    # Maxpooling the data (sample,22,800) -> (sample,22,800/sub_sample)\n",
    "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
    "\n",
    "\n",
    "    total_X = X_max\n",
    "    total_y = y\n",
    "    print('Shape of X after maxpooling:',total_X.shape)\n",
    "\n",
    "    # Averaging + noise\n",
    "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
    "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
    "\n",
    "    # Data augmentation: increases number of samples (max pool and mean pool +noise)\n",
    "    total_X = np.vstack((total_X, X_average))\n",
    "    total_y = np.hstack((total_y, y))\n",
    "    print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
    "\n",
    "    # Subsampling\n",
    "\n",
    "    for i in range(sub_sample):\n",
    "\n",
    "        X_subsample = X[:, :, i::sub_sample] + \\\n",
    "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
    "\n",
    "        total_X = np.vstack((total_X, X_subsample))\n",
    "        total_y = np.hstack((total_y, y))\n",
    "\n",
    "\n",
    "    print('Shape of X after subsampling and concatenating:',total_X.shape)\n",
    "    print('Shape of Y:',total_y.shape)\n",
    "    return total_X,total_y\n",
    "\n",
    "\n",
    "# Don't increase the number of test samples\n",
    "def test_data_prep(X):\n",
    "\n",
    "    total_X = None\n",
    "\n",
    "\n",
    "    # Trimming the data (sample,22,1000) -> (sample,22,800)\n",
    "    X = X[:,:,0:800]\n",
    "    print('Shape of X after trimming:',X.shape)\n",
    "\n",
    "    # Maxpooling the data (sample,22,800) -> (sample,22,800/sub_sample)\n",
    "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, 2), axis=3)\n",
    "\n",
    "\n",
    "    total_X = X_max\n",
    "    print('Shape of X after maxpooling:',total_X.shape)\n",
    "\n",
    "    return total_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68084d74-c57d-4424-b6f1-5da7d2f9d59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after trimming: (1115, 22, 800)\n",
      "Shape of X after maxpooling: (1115, 22, 400)\n",
      "Shape of X after averaging+noise and concatenating: (2230, 22, 400)\n",
      "Shape of X after subsampling and concatenating: (4460, 22, 400)\n",
      "Shape of Y: (4460,)\n",
      "Shape of X after trimming: (1000, 22, 800)\n",
      "Shape of X after maxpooling: (1000, 22, 400)\n",
      "Shape of X after averaging+noise and concatenating: (2000, 22, 400)\n",
      "Shape of X after subsampling and concatenating: (4000, 22, 400)\n",
      "Shape of Y: (4000,)\n",
      "Shape of X after trimming: (443, 22, 800)\n",
      "Shape of X after maxpooling: (443, 22, 400)\n"
     ]
    }
   ],
   "source": [
    "# Train val split, then data augment the training set\n",
    "ind_valid = np.random.choice(X_train_valid.shape[0], 1000, replace=False)\n",
    "ind_train = np.array(list(set(range(X_train_valid.shape[0])).difference(set(ind_valid))))\n",
    "# Creating the training and validation sets using the generated indices\n",
    "(x_train_unprocessed, x_valid) = X_train_valid[ind_train], X_train_valid[ind_valid]\n",
    "(y_train_unprocessed, y_valid) = y_train_valid[ind_train], y_train_valid[ind_valid]\n",
    "\n",
    "x_train, y_train = train_data_prep(x_train_unprocessed, y_train_unprocessed,2,2,True)\n",
    "x_valid, y_valid = train_data_prep(x_valid, y_valid, 2, 2, True)\n",
    "X_test_prep = test_data_prep(X_test)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_valid.shape[2], 1)\n",
    "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "x_train = np.swapaxes(x_train, 1,3)\n",
    "x_train = np.swapaxes(x_train, 1,2)\n",
    "x_valid = np.swapaxes(x_valid, 1,3)\n",
    "x_valid = np.swapaxes(x_valid, 1,2)\n",
    "x_test = np.swapaxes(x_test, 1,3)\n",
    "x_test = np.swapaxes(x_test, 1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4380e0ee-92d3-4a68-be97-ad4cfa76a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1,400,22)\n",
    "x_valid = x_valid.reshape(-1,400,22)\n",
    "x_test = x_test.reshape(-1,400,22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c11f3ba7-5e8d-42c6-9ba4-1eb4bf9ee829",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c70aec0-8f78-4a9a-8dbf-c84e140499f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainds = CustomDataset(x_train, y_train-769)\n",
    "testds = CustomDataset(x_test, y_test-769)\n",
    "validds = CustomDataset(x_valid, y_valid-769)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b0c2647-64a4-4b6c-943d-b95640b7d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import default_collate, DataLoader\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0')  # or whatever device/cpu you like\n",
    "\n",
    "# the new collate function is quite generic\n",
    "trainloader = DataLoader(trainds, batch_size=100, shuffle=True, \n",
    "                    collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))\n",
    "testloader = DataLoader(testds, batch_size=100, shuffle=True, \n",
    "                    collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))\n",
    "validloader = DataLoader(validds, batch_size=100, shuffle=True, \n",
    "                    collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b4b91ef-f415-4278-a9a7-a1da9c4c32ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PatchTSMixerConfig, PatchTSMixerForTimeSeriesClassification\n",
    "\n",
    "config = PatchTSMixerConfig(num_targets=4, context_length=400, num_input_channels=22)\n",
    "model = PatchTSMixerForTimeSeriesClassification(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3af40c28-1bee-4676-a541-8e5bf97e0fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5bcda0ac-85eb-4a64-8995-5ca27f68de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c989269-53b3-4014-a19d-f618a5df70ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1.3867128610610961\n",
      "Loss 1.375259115960863\n",
      "Loss 1.3593898190392388\n",
      "Loss 1.3175734281539917\n",
      "Loss 1.2632429997126262\n",
      "Loss 1.1841843181186251\n",
      "Loss 1.0924112677574158\n",
      "Loss 0.981871849960751\n",
      "Loss 0.8621355295181274\n",
      "Loss 0.7446977112028333\n",
      "Loss 0.6572926388846503\n",
      "Loss 0.5630249268478817\n",
      "Loss 0.4786636041270362\n",
      "Loss 0.4162093844678667\n",
      "Loss 0.36632757518026565\n",
      "Loss 0.3167005148198869\n",
      "Loss 0.28135286072889965\n",
      "Loss 0.2384997116194831\n",
      "Loss 0.21117081162002352\n",
      "Loss 0.19790394256512325\n",
      "Loss 0.16916111989153756\n",
      "Loss 0.1554706742366155\n",
      "Loss 0.15046215918329026\n",
      "Loss 0.13974852826860215\n",
      "Loss 0.137945752342542\n",
      "Loss 0.11085463290413221\n",
      "Loss 0.09187483675777912\n",
      "Loss 0.09383437385161718\n",
      "Loss 0.10832820944488049\n",
      "Loss 0.10006634154253535\n",
      "Loss 0.08400162677798007\n",
      "Loss 0.0796561380641328\n",
      "Loss 0.08492441231177913\n",
      "Loss 0.07336901914742258\n",
      "Loss 0.07899233305619822\n",
      "Loss 0.0701573423213429\n",
      "Loss 0.06509431170092689\n",
      "Loss 0.059991248945395155\n",
      "Loss 0.06615930282407337\n",
      "Loss 0.050590035174455907\n",
      "Loss 0.049682516273525025\n",
      "Loss 0.05027072166817056\n",
      "Loss 0.050153732486069205\n",
      "Loss 0.050389853078458044\n",
      "Loss 0.05908101511498292\n",
      "Loss 0.05092389370418257\n",
      "Loss 0.05081671310795678\n",
      "Loss 0.044841912016272543\n",
      "Loss 0.040494828816089366\n",
      "Loss 0.040867883546484844\n",
      "Loss 0.03730587652987904\n",
      "Loss 0.04963956887109412\n",
      "Loss 0.044922587523857756\n",
      "Loss 0.03180506937205792\n",
      "Loss 0.0328206169936392\n",
      "Loss 0.03426810141859783\n",
      "Loss 0.04530179926918613\n",
      "Loss 0.047059213421824904\n",
      "Loss 0.036074021417233676\n",
      "Loss 0.03157077843530311\n",
      "Loss 0.04812696983830796\n",
      "Loss 0.045466533029038046\n",
      "Loss 0.040232447141574486\n",
      "Loss 0.028899958295126756\n",
      "Loss 0.027551111165020202\n",
      "Loss 0.02982251457352605\n",
      "Loss 0.030478460155427455\n",
      "Loss 0.030031606617073218\n",
      "Loss 0.027704311721026897\n",
      "Loss 0.025977382260478205\n",
      "Loss 0.040602542863537865\n",
      "Loss 0.03649570398653547\n",
      "Loss 0.029636480322935515\n",
      "Loss 0.027017168881785538\n",
      "Loss 0.03136676847417322\n",
      "Loss 0.04154192361359795\n",
      "Loss 0.022257622765998044\n",
      "Loss 0.02729241091551052\n",
      "Loss 0.026725690118554565\n",
      "Loss 0.03229636638425291\n"
     ]
    }
   ],
   "source": [
    "for i in range(80):\n",
    "    losses = []\n",
    "    for x,y in trainloader:\n",
    "        x = x.to(torch.float)\n",
    "        y = y.to(torch.long)\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(x)[0]\n",
    "        loss = criterion(yhat, y)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Loss {sum(losses)/len(losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eef0e0c9-353a-4b4c-95e5-cab079b99ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3064651162790698\n"
     ]
    }
   ],
   "source": [
    "avgs = []\n",
    "for x,y in testloader:\n",
    "    x = x.to(torch.float)\n",
    "    y = y.to(torch.long)\n",
    "    yhat = model(x)[0]\n",
    "    avgs.append((yhat.argmax(dim=-1)==y).sum().item()/x.shape[0])\n",
    "print(sum(avgs) / len(avgs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
